{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7805060,"sourceType":"datasetVersion","datasetId":4570601},{"sourceId":7835615,"sourceType":"datasetVersion","datasetId":4592882}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nelectron_dataset = h5py.File('/kaggle/input/electron-photon-dataset/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5', 'r')\nphoton_dataset = h5py.File('/kaggle/input/electron-photon-dataset/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5', 'r')\n\nelectron_dataset.keys()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:14:16.183948Z","iopub.execute_input":"2024-03-17T15:14:16.184746Z","iopub.status.idle":"2024-03-17T15:14:16.344347Z","shell.execute_reply.started":"2024-03-17T15:14:16.184695Z","shell.execute_reply":"2024-03-17T15:14:16.343491Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<KeysViewHDF5 ['X', 'y']>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nfrom torch.utils.data import Dataset, ConcatDataset\nimport torch\nfrom torchvision.transforms import ToTensor, Compose, Resize, Lambda\nfrom torch.utils.data import Subset\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass FullDataset(Dataset):\n    def __init__(self, data, transform):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return self.data['y'].shape[0]\n\n    def __getitem__(self, idx):\n        return self.transform(self.data['X'][idx]), self.data['y'][idx]\n\n\ntransform = Compose([\n    ToTensor(),\n#     Resize((128,128)),\n#     Lambda(lambd= lambda x: torch.cat([x, torch.zeros([1, 128, 128])], dim=0))\n])\n\nelectron = FullDataset(electron_dataset, transform=transform)\nphoton = FullDataset(photon_dataset, transform=transform)\n\nfull = ConcatDataset([electron, photon])\n\nrandom_indices = np.random.choice(len(full), size=10000, replace=False)\n\nsmall_dataset = Subset(full, random_indices)\n\ntrain_data, test_data = random_split(small_dataset, [0.8, 0.2])\n\n\nbatch_size = 64\n\ntrain_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True,)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n\ndevice = 'cuda'\n\nfrom tqdm import tqdm\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = None\n        if stride != 1 or in_channels != out_channels:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        identity = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample is not None:\n            identity = self.downsample(x)\n        out += identity\n        out = self.relu(out)\n        return out\n\nclass Model(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(Model, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.residual_block = ResidualBlock(out_channels, out_channels)\n        self.fc = nn.Linear(320, 2)  # Linear layer after the ResNet block\n\n    def forward(self, x):\n        out = self.conv(x)\n        out = self.residual_block(out)\n        out = F.avg_pool2d(out, 4)  # Example downsampling operation\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out\n\nmodel = Model(2, 5).float().to(device)\n\nfrom torch.utils.data import Subset\nimport numpy as np\n\n\ndef evaluate(loader, model):\n    model.eval()\n    total_loss = 0.0\n    correct = 0\n    total_samples = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(loader):\n\n            pred = model(batch[0].to(device))\n\n            pred_labels = torch.sigmoid(pred).argmax(dim=-1)\n            correct += (pred_labels == batch[1].to(device)).sum().item()\n            total_samples += len(batch[1].to(device))\n\n    return correct/total_samples","metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:14:29.401134Z","iopub.execute_input":"2024-03-17T15:14:29.401924Z","iopub.status.idle":"2024-03-17T15:14:35.507837Z","shell.execute_reply.started":"2024-03-17T15:14:29.401893Z","shell.execute_reply":"2024-03-17T15:14:35.506856Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"num_epochs = 15\nbest_acc = 0\n\ncriterion = nn.CrossEntropyLoss()\noptimiser = torch.optim.AdamW(model.parameters(), lr=3e-4)\n\nfor epoch in range(1, num_epochs+1):\n    epoch_loss = 0\n    model.train()\n    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch}:'):\n        # print(f'{i}/{len(train_dataloader)}')\n        # print(batch[1],batch[1].shape)\n\n        pred = model(batch[0].to(device))\n        # print(pred, pred.shape)\n        loss = criterion(pred, batch[1].long().to(device))\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        epoch_loss += loss.item()\n    acc = evaluate(test_dataloader, model)\n    print(f'Loss after f{epoch} epochs = {epoch_loss}, Val acc = {100*acc}%')\n    if acc > best_acc:\n        best_acc = acc\n        best_epoch = epoch\n        torch.save(model.state_dict(), f'/kaggle/working/{epoch}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:18:36.111536Z","iopub.execute_input":"2024-03-17T15:18:36.112293Z","iopub.status.idle":"2024-03-17T21:48:20.000266Z","shell.execute_reply.started":"2024-03-17T15:18:36.112262Z","shell.execute_reply":"2024-03-17T21:48:19.999365Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Epoch 1:: 100%|██████████| 125/125 [20:47<00:00,  9.98s/it]\n100%|██████████| 32/32 [05:11<00:00,  9.73s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f1 epochs = 86.44747442007065, Val acc = 56.599999999999994%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:: 100%|██████████| 125/125 [20:48<00:00,  9.99s/it]\n100%|██████████| 32/32 [05:11<00:00,  9.73s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f2 epochs = 85.28908115625381, Val acc = 57.550000000000004%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:: 100%|██████████| 125/125 [20:54<00:00, 10.04s/it]\n100%|██████████| 32/32 [05:14<00:00,  9.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f3 epochs = 84.45879954099655, Val acc = 57.49999999999999%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:: 100%|██████████| 125/125 [20:48<00:00,  9.98s/it]\n100%|██████████| 32/32 [05:11<00:00,  9.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f4 epochs = 83.70755857229233, Val acc = 58.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:: 100%|██████████| 125/125 [20:51<00:00, 10.01s/it]\n100%|██████████| 32/32 [05:14<00:00,  9.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f5 epochs = 83.34814894199371, Val acc = 59.4%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:: 100%|██████████| 125/125 [20:47<00:00,  9.98s/it]\n100%|██████████| 32/32 [05:12<00:00,  9.77s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f6 epochs = 82.91225200891495, Val acc = 58.8%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:: 100%|██████████| 125/125 [20:46<00:00,  9.97s/it]\n100%|██████████| 32/32 [05:10<00:00,  9.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f7 epochs = 82.87983494997025, Val acc = 59.8%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:: 100%|██████████| 125/125 [20:42<00:00,  9.94s/it]\n100%|██████████| 32/32 [05:09<00:00,  9.68s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f8 epochs = 82.60226565599442, Val acc = 59.35%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:: 100%|██████████| 125/125 [20:45<00:00,  9.97s/it]\n100%|██████████| 32/32 [05:14<00:00,  9.83s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f9 epochs = 82.43799072504044, Val acc = 59.650000000000006%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:: 100%|██████████| 125/125 [20:45<00:00,  9.96s/it]\n100%|██████████| 32/32 [05:11<00:00,  9.73s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f10 epochs = 82.24004679918289, Val acc = 59.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11:: 100%|██████████| 125/125 [20:41<00:00,  9.93s/it]\n100%|██████████| 32/32 [05:10<00:00,  9.70s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f11 epochs = 82.43570989370346, Val acc = 60.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12:: 100%|██████████| 125/125 [20:39<00:00,  9.92s/it]\n100%|██████████| 32/32 [05:09<00:00,  9.67s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f12 epochs = 82.04974013566971, Val acc = 59.95%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13:: 100%|██████████| 125/125 [20:50<00:00, 10.01s/it]\n100%|██████████| 32/32 [05:13<00:00,  9.79s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f13 epochs = 81.91537237167358, Val acc = 59.95%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14:: 100%|██████████| 125/125 [20:47<00:00,  9.98s/it]\n100%|██████████| 32/32 [05:12<00:00,  9.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f14 epochs = 81.78760993480682, Val acc = 59.650000000000006%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15:: 100%|██████████| 125/125 [20:46<00:00,  9.97s/it]\n100%|██████████| 32/32 [05:12<00:00,  9.78s/it]","output_type":"stream"},{"name":"stdout","text":"Loss after f15 epochs = 81.78811627626419, Val acc = 60.35%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(1, num_epochs+1):\n    epoch_loss = 0\n    model.train()\n    for batch in tqdm(train_dataloader, desc=f'Epoch {num_epochs+epoch}:'):\n        # print(f'{i}/{len(train_dataloader)}')\n        # print(batch[1],batch[1].shape)\n\n        pred = model(batch[0].to(device))\n        # print(pred, pred.shape)\n        loss = criterion(pred, batch[1].long().to(device))\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        epoch_loss += loss.item()\n    acc = evaluate(test_dataloader, model)\n    print(f'Loss after {num_epochs+epoch} epochs = {epoch_loss}, Val acc = {100*acc}%')\n    if acc > best_acc:\n        best_acc = acc\n        best_epoch = epoch\n        torch.save(model.state_dict(), f'/kaggle/working/{num_epochs+epoch}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-03-17T21:48:20.002083Z","iopub.execute_input":"2024-03-17T21:48:20.002481Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 16:: 100%|██████████| 125/125 [20:46<00:00,  9.97s/it]\n100%|██████████| 32/32 [05:10<00:00,  9.71s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 16 epochs = 81.50043708086014, Val acc = 60.050000000000004%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17:: 100%|██████████| 125/125 [20:44<00:00,  9.96s/it]\n100%|██████████| 32/32 [05:11<00:00,  9.74s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 17 epochs = 81.71386760473251, Val acc = 59.4%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18:: 100%|██████████| 125/125 [20:47<00:00,  9.98s/it]\n100%|██████████| 32/32 [05:11<00:00,  9.73s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 18 epochs = 81.30803221464157, Val acc = 60.35%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19:: 100%|██████████| 125/125 [20:51<00:00, 10.01s/it]\n100%|██████████| 32/32 [05:14<00:00,  9.84s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 19 epochs = 81.26681661605835, Val acc = 60.25%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20:: 100%|██████████| 125/125 [20:59<00:00, 10.08s/it]\n100%|██████████| 32/32 [05:14<00:00,  9.83s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 20 epochs = 81.20397907495499, Val acc = 60.550000000000004%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21:: 100%|██████████| 125/125 [20:56<00:00, 10.05s/it]\n100%|██████████| 32/32 [05:12<00:00,  9.77s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 21 epochs = 81.19562822580338, Val acc = 60.199999999999996%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22:: 100%|██████████| 125/125 [20:53<00:00, 10.03s/it]\n100%|██████████| 32/32 [05:13<00:00,  9.81s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 22 epochs = 80.97035294771194, Val acc = 59.650000000000006%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23:: 100%|██████████| 125/125 [21:02<00:00, 10.10s/it]\n100%|██████████| 32/32 [05:15<00:00,  9.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 23 epochs = 80.81147682666779, Val acc = 60.3%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24:: 100%|██████████| 125/125 [20:59<00:00, 10.07s/it]\n100%|██████████| 32/32 [05:14<00:00,  9.83s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 24 epochs = 80.93522256612778, Val acc = 60.35%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25:: 100%|██████████| 125/125 [21:00<00:00, 10.09s/it]\n100%|██████████| 32/32 [05:14<00:00,  9.82s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 25 epochs = 80.62047773599625, Val acc = 60.550000000000004%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26:: 100%|██████████| 125/125 [20:58<00:00, 10.07s/it]\n100%|██████████| 32/32 [05:15<00:00,  9.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 26 epochs = 80.64774167537689, Val acc = 60.35%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27:: 100%|██████████| 125/125 [21:01<00:00, 10.09s/it]\n100%|██████████| 32/32 [05:15<00:00,  9.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 27 epochs = 80.67484217882156, Val acc = 60.0%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28::  49%|████▉     | 61/125 [10:16<10:44, 10.08s/it]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}