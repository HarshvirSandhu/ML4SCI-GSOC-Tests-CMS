{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7805060,"sourceType":"datasetVersion","datasetId":4570601}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nelectron_dataset = h5py.File('/kaggle/input/electron-photon-dataset/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5', 'r')\nphoton_dataset = h5py.File('/kaggle/input/electron-photon-dataset/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5', 'r')","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:06:35.939783Z","iopub.execute_input":"2024-03-10T07:06:35.940594Z","iopub.status.idle":"2024-03-10T07:06:36.103532Z","shell.execute_reply.started":"2024-03-10T07:06:35.940530Z","shell.execute_reply":"2024-03-10T07:06:36.102568Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"electron_dataset.keys()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:06:36.265778Z","iopub.execute_input":"2024-03-10T07:06:36.266343Z","iopub.status.idle":"2024-03-10T07:06:36.273374Z","shell.execute_reply.started":"2024-03-10T07:06:36.266311Z","shell.execute_reply":"2024-03-10T07:06:36.272441Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<KeysViewHDF5 ['X', 'y']>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\nfrom torch.utils.data import Dataset, ConcatDataset\n\n\nclass FullDataset(Dataset):\n    def __init__(self, data, transform):\n        self.data = data\n        self.transform = transform\n    \n    def __len__(self):\n        return self.data['y'].shape[0]\n\n    def __getitem__(self, idx):\n        return self.transform(self.data['X'][idx]), self.data['y'][idx]","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:07:14.474952Z","iopub.execute_input":"2024-03-10T07:07:14.475311Z","iopub.status.idle":"2024-03-10T07:07:17.694060Z","shell.execute_reply.started":"2024-03-10T07:07:14.475282Z","shell.execute_reply":"2024-03-10T07:07:17.693253Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision.transforms import ToTensor, Compose, Resize, Lambda\n\ntransform = Compose([\n    ToTensor(),\n    Resize((128,128)),\n    Lambda(lambd= lambda x: torch.cat([x, torch.zeros([1, 128, 128])], dim=0))\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:07:25.128505Z","iopub.execute_input":"2024-03-10T07:07:25.129020Z","iopub.status.idle":"2024-03-10T07:07:27.884353Z","shell.execute_reply.started":"2024-03-10T07:07:25.128989Z","shell.execute_reply":"2024-03-10T07:07:27.883552Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"electron = FullDataset(electron_dataset, transform=transform)\nphoton = FullDataset(photon_dataset, transform=transform)\n\nfull = ConcatDataset([electron, photon])\n\ntrain_data, test_data = random_split(full, [0.8, 0.2])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:08:33.499779Z","iopub.execute_input":"2024-03-10T07:08:33.500573Z","iopub.status.idle":"2024-03-10T07:08:33.573175Z","shell.execute_reply.started":"2024-03-10T07:08:33.500527Z","shell.execute_reply":"2024-03-10T07:08:33.572171Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Subset\nimport numpy as np\n\n\nrandom_indices = np.random.choice(len(train_data), size=40000, replace=False)\n\nsmall_train_dataset = Subset(train_data, random_indices)\n\nbatch_size = 64\n\ntrain_dataloader = DataLoader(small_train_dataset, batch_size=batch_size, shuffle=True,)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:08:54.325599Z","iopub.execute_input":"2024-03-10T07:08:54.326207Z","iopub.status.idle":"2024-03-10T07:08:54.344911Z","shell.execute_reply.started":"2024-03-10T07:08:54.326175Z","shell.execute_reply":"2024-03-10T07:08:54.344056Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:12:41.004757Z","iopub.execute_input":"2024-03-10T07:12:41.005114Z","iopub.status.idle":"2024-03-10T07:12:41.009527Z","shell.execute_reply.started":"2024-03-10T07:12:41.005085Z","shell.execute_reply":"2024-03-10T07:12:41.008597Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass ResNet15(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n\n        # Initial convolution\n        self.conv1 = conv_block(in_channels, 64)\n\n        # Residual blocks\n        self.res1 = nn.Sequential(conv_block(64, 64), conv_block(64, 64))\n        self.conv2 = conv_block(64, 128, stride=2)  # Downsample using stride\n        self.res2 = nn.Sequential(conv_block(128, 128), conv_block(128, 128), conv_block(128, 128))\n        self.conv3 = conv_block(128, 512, stride=2)  # Downsample using stride\n        self.res3 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n        self.conv4 = conv_block(512, 1024, stride=2)  # Downsample using stride\n        self.res4 = nn.Sequential(conv_block(1024, 1024), conv_block(1024, 1024))\n\n        # Classifier\n        self.classifier = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),  # Global average pooling\n            nn.Flatten(),\n            nn.Dropout(0.2),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1)  # Adjust output size for classification (assuming 2 classes)\n        )\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.res1(x) + x  # Residual connection\n        x = self.conv2(x)\n        x = self.res2(x) + x  # Residual connection\n        x = self.conv3(x)\n        x = self.res3(x) + x  # Residual connection\n        x = self.conv4(x)\n        x = self.res4(x) + x  # Residual connection\n        x = self.classifier(x)\n        return x\n\ndef conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU()\n    )\n\nmodel = ResNet15(3).float().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:12:49.588712Z","iopub.execute_input":"2024-03-10T07:12:49.589073Z","iopub.status.idle":"2024-03-10T07:12:49.918013Z","shell.execute_reply.started":"2024-03-10T07:12:49.589045Z","shell.execute_reply":"2024-03-10T07:12:49.917232Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ncriterion = nn.BCELoss()\noptimiser = torch.optim.AdamW(model.parameters(), lr=3e-4)\nnum_epochs = 5\n\nfor epoch in range(1, num_epochs+1):\n    epoch_loss = 0\n    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch}:'):\n        # print(f'{i}/{len(train_dataloader)}')\n        # print(batch[1],batch[1].shape)\n\n        pred = model(batch[0].to(device))\n        # print(pred, pred.shape)\n        loss = criterion(torch.sigmoid(pred).squeeze(-1), batch[1].float().to(device))\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        epoch_loss += loss.item()\n    print(f'Loss after {epoch} epochs = {epoch_loss}')\n    torch.save(model.state_dict(), f'/kaggle/working/Resnet15-Epoch_{epoch}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-03-10T07:12:50.164741Z","iopub.execute_input":"2024-03-10T07:12:50.165083Z","iopub.status.idle":"2024-03-10T16:17:27.896614Z","shell.execute_reply.started":"2024-03-10T07:12:50.165057Z","shell.execute_reply":"2024-03-10T16:17:27.895621Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Epoch 1::   0%|          | 0/625 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\nEpoch 1:: 100%|██████████| 625/625 [1:49:18<00:00, 10.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f1 epochs = 415.2847344279289\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:: 100%|██████████| 625/625 [1:49:13<00:00, 10.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f2 epochs = 391.9993373155594\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:: 100%|██████████| 625/625 [1:48:21<00:00, 10.40s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f3 epochs = 382.91221472620964\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:: 100%|██████████| 625/625 [1:48:38<00:00, 10.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f4 epochs = 376.4430049955845\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:: 100%|██████████| 625/625 [1:49:05<00:00, 10.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after f5 epochs = 371.85460218787193\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(1, num_epochs+1):\n    epoch_loss = 0\n    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch}:'):\n        # print(f'{i}/{len(train_dataloader)}')\n        # print(batch[1],batch[1].shape)\n\n        pred = model(batch[0].to(device))\n        # print(pred, pred.shape)\n        loss = criterion(torch.sigmoid(pred).squeeze(-1), batch[1].float().to(device))\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        epoch_loss += loss.item()\n    print(f'Loss after {epoch+num_epochs} epochs = {epoch_loss}')\n    torch.save(model.state_dict(), f'/kaggle/working/Resnet15-Epoch_{epoch+num_epochs}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-03-10T16:24:07.534964Z","iopub.execute_input":"2024-03-10T16:24:07.535332Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1:: 100%|██████████| 625/625 [1:49:14<00:00, 10.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Loss after 6 epochs = 366.11900609731674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2::  48%|████▊     | 302/625 [52:38<56:36, 10.51s/it]  ","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}