{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bKK5mNqex6vt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pyarrow.parquet as parquet\n",
        "first = 'QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet'\n",
        "second = 'QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet'\n",
        "third = 'QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKzdTmUIyfwZ",
        "outputId": "e188d77e-c514-44b3-ab2a-d7cef6a1cfb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\Total Number of Row Groups: 36272\n"
          ]
        }
      ],
      "source": [
        "parquet_file = parquet.ParquetFile('/content/drive/MyDrive/Sci_data/'+first)\n",
        "\n",
        "num_row_groups = parquet_file.num_row_groups\n",
        "\n",
        "print(\"\\Total Number of Row Groups:\", num_row_groups)\n",
        "\n",
        "chunk_size =3000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Due to computational constraints, the complete dataset cannot be read at once. Instead, chunks of data are read from the dataset and are later saved as `.pt` files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM2s6GnNuW7I",
        "outputId": "118775b4-729a-4431-f520-8f37bf3141da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RecordBatch\n"
          ]
        }
      ],
      "source": [
        "chunk_num = 1\n",
        "for batch in parquet_file.iter_batches(chunk_size):\n",
        "    print(\"RecordBatch\")\n",
        "    batch_df = batch.to_pandas()\n",
        "    chunk_num -=1\n",
        "    if chunk_num == 0:\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8WDT-2d9jmM",
        "outputId": "7d56d83e-c4ba-46da-f5ae-82116931ef57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0    1520\n",
              "1.0    1480\n",
              "Name: y, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_df['y'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnS-W7fkweTL"
      },
      "source": [
        "## Converting Image Dataset to Graph Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CndXdubT4whY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "img_list = []\n",
        "\n",
        "limit = chunk_size\n",
        "for number in range(limit):\n",
        "  for idx, channels in enumerate(batch_df['X_jets'][number]):\n",
        "    for i, row in enumerate(channels):\n",
        "      if i==0:\n",
        "        img = row\n",
        "      else:\n",
        "        img = np.vstack([img, row])\n",
        "    if idx==0:\n",
        "      final_img = img\n",
        "    else:\n",
        "      final_img = np.dstack([final_img, img])\n",
        "  img_list.append(final_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pXu4GjaukWWK"
      },
      "outputs": [],
      "source": [
        "mini_df = batch_df[['pt', 'm0',\t'y']]\n",
        "del batch_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cx6hKI_HiTX3"
      },
      "outputs": [],
      "source": [
        "x_jet = np.array(img_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMUi2o4j8oLI",
        "outputId": "c419ff37-c148-4529-98cd-d3a9d6f87bfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3000, 15625, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_jet.reshape((chunk_size, -1, 3)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "N2j591uy-0MN"
      },
      "outputs": [],
      "source": [
        "X_data = x_jet.reshape((chunk_size, -1, 3))\n",
        "del img_list\n",
        "del x_jet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Sb4Q8O2-8pki"
      },
      "outputs": [],
      "source": [
        "unmasked = np.any(X_data != 0., axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWGnrM6K-Ajy",
        "outputId": "b38e4cbe-f99e-4e91-ccb8-2238cbd4a76b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3000, 15625)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unmasked.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cx_l9iHy-Fe7"
      },
      "outputs": [],
      "source": [
        "node_list = []\n",
        "for i, x in enumerate(X_data):\n",
        "    node_list.append(x[unmasked[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4IY9UzDflrfJ"
      },
      "outputs": [],
      "source": [
        "del unmasked\n",
        "del X_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-oHaiXxHESWj"
      },
      "outputs": [],
      "source": [
        "y = mini_df['y'].to_numpy()\n",
        "y = y.reshape((-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPCPAZ6OCIbA",
        "outputId": "07485638-37ca-4368-9e66-ae9ac80b726b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [00:17<00:00, 172.52it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "dataset = []\n",
        "for i,nodes in enumerate(tqdm(node_list)):\n",
        "    dummy = mini_df['m0'][i]*np.ones((nodes.shape[0],1))\n",
        "    dummy2 = mini_df['pt'][i]*np.ones((nodes.shape[0],1))\n",
        "    nodes = np.concatenate([nodes, dummy, dummy2], axis=-1)\n",
        "    edges = kneighbors_graph(nodes, 10, mode='connectivity', include_self=True)\n",
        "    c = edges.tocoo()\n",
        "    # print(c)\n",
        "    edge_list = torch.from_numpy(np.vstack((c.row, c.col))).type(torch.long)\n",
        "    edge_weight = torch.from_numpy(c.data.reshape(-1,1))\n",
        "    y_g = y[i]\n",
        "    # print(type(torch.from_numpy(nodes)), type(edge_list), type(edge_weight))\n",
        "    dataset.append(Data(x=torch.from_numpy(nodes), edge_index=edge_list, edge_attr=edge_weight, y=torch.from_numpy(y_g).long()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMNp3TK4Cu6Z",
        "outputId": "a419ea81-56ec-4f6c-a063-0225ffee8508"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[717, 5], edge_index=[2, 7170], edge_attr=[7170, 1], y=[1])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "s0AHf5WhFZRC"
      },
      "outputs": [],
      "source": [
        "torch.save(dataset, '/content/drive/MyDrive/Sci_data/first.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "995QQligjq4Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
